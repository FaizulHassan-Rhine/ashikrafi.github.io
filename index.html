<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Md Ashikur Rahman</title>

  <meta name="author" content="Md Ashikur Rahman">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="./Kelsey Allen_files/stylesheet.css">
  <link rel="icon" type="image/png" href="https://web.mit.edu/krallen/www/images/brain.jpg">
<style type="text/css">.__react_component_tooltip {
  border-radius: 3px;
  display: inline-block;
  font-size: 13px;
  left: -999em;
  opacity: 0;
  padding: 8px 21px;
  position: fixed;
  pointer-events: none;
  transition: opacity 0.3s ease-out;
  top: -999em;
  visibility: hidden;
  z-index: 999;
}
.__react_component_tooltip.allow_hover, .__react_component_tooltip.allow_click {
  pointer-events: auto;
}
.__react_component_tooltip::before, .__react_component_tooltip::after {
  content: "";
  width: 0;
  height: 0;
  position: absolute;
}
.__react_component_tooltip.show {
  opacity: 0.9;
  margin-top: 0;
  margin-left: 0;
  visibility: visible;
}
.__react_component_tooltip.place-top::before {
  border-left: 10px solid transparent;
  border-right: 10px solid transparent;
  bottom: -8px;
  left: 50%;
  margin-left: -10px;
}
.__react_component_tooltip.place-bottom::before {
  border-left: 10px solid transparent;
  border-right: 10px solid transparent;
  top: -8px;
  left: 50%;
  margin-left: -10px;
}
.__react_component_tooltip.place-left::before {
  border-top: 6px solid transparent;
  border-bottom: 6px solid transparent;
  right: -8px;
  top: 50%;
  margin-top: -5px;
}
.__react_component_tooltip.place-right::before {
  border-top: 6px solid transparent;
  border-bottom: 6px solid transparent;
  left: -8px;
  top: 50%;
  margin-top: -5px;
}
.__react_component_tooltip .multi-line {
  display: block;
  padding: 2px 0;
  text-align: center;
}</style><style type="text/css">/* add css styles here (optional) */

.styles_react-code-input-container__tpiKG {
  position: relative;
}

.styles_react-code-input__CRulA > input {
  border: solid 1px #a8adb7;
  border-right: none;
  font-family: 'Lato';
  font-size: 20px;
  color: #525461;
  text-align: center;
  box-sizing: border-box;
  border-radius: 0;
  -webkit-appearance: initial;
}

.styles_react-code-input__CRulA > input:last-child {
  border-right: solid 1px #a8adb7;
  border-top-right-radius: 6px;
  border-bottom-right-radius: 6px;
}

.styles_react-code-input__CRulA > input:first-child {
  border-top-left-radius: 6px;
  border-bottom-left-radius: 6px;
}

.styles_react-code-input__CRulA > input:focus {
  outline: none;
  border: 1px solid #006fff;
  caret-color: #006fff;
}

.styles_react-code-input__CRulA > input:focus + input {
  border-left: none;
}

.styles_loading__Z65VQ {
  position: absolute;
  left: 0;
  right: 0;
  bottom: 0;
  text-align: center;
}

.styles_blur__19vMK {
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background-color: #fff;
  opacity: 0.5;
  filter: blur(0.5px);
  transition: opacity 0.3s;
}

.styles_title__1cca0 {
  margin: 0;
  height: 20px;
  padding-bottom: 10px;
}

.styles_spin__6y_8G {
  display: inline-block;
  animation: styles_loadingCircle__293ky 1s infinite linear;
}

@keyframes styles_loadingCircle__293ky {
  100% {
    transform: rotate(360deg);
  }
}
</style></head>

<body data-new-gr-c-s-check-loaded="14.1022.0" data-gr-ext-installed="">
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <h2>Md Ashikur Rahman</h2>
              </p>
              <p>
                I am currently a Machine Learning Engineer at <a href="https://cutoutwiz.com/" target="=_blank">CutOutWiz</a>. I received my B.Sc. from <a href="https://www.aiub.edu/" target="=_blank">American International University-Bangladesh (AIUB)</a> in CSE and completed my undergraduate thesis under the supervision of <a href="http://cs.aiub.edu/profile/tabin" target="=_blank">Dr. Tabin Hasan</a> at AIUB,
              </p>
              <p style="text-align:center">
                <a href="mailto:ashik.rafi@hotmail.com" target="=_blank">Email</a> &nbsp;&nbsp;
                <a href="https://www.linkedin.com/in/mdashikrah/" target="=_blank">Linkedin</a> &nbsp;&nbsp;
                <a href="https://github.com/ashikrafi/" target="=_blank">GitHub</a> &nbsp;&nbsp;
                <a href="https://scholar.google.com/citations?user=Htgw_vEAAAAJ&amp;hl=en" target="=_blank">Google Scholar</a> &nbsp;&nbsp;
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="Images/ProfilePic.jpg"><img style="width:80%;max-width:80%" alt="profile photo" src="Images/ProfilePic.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h4>Research Interests</h4>
              <p>
               I am interested in Graph Algorithm, Natural Language Processing, Deep Learning, and Machine Learning. Considering my long-term goals, I want a research career. However, I have always been compelled to understand the world around me and to find out how things work.
              <p></p>
                <strong>Selected Projects for Image Processing</strong>
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>

            <td width="25%">
              <div class="one">
                <div class="two"><img src="Images/IBR.jpg" width="160"></div>
              </div>
            </td>
            <td valign="middle" width="75%">
            <a href="#">
                <papertitle>Deep Network Architectures for Object Detection and Segmentation</papertitle>
            </a>
              <br>
              <strong>Md Ashikur Rahman</strong>, Md Arifur Rahman @<a href="https://cutoutwiz.com/" target="=_blank">CutOutWiz</a>
              <br>
              <a href="https://bnia.basis.org.bd/" target="_blank">BASIS NATIONAL ICT AWARDS-2020</a><font color="red"><strong>(CHAMPION)</strong></font><br>
              <font color="green"><strong>QUALIFIED for </strong></font><a href="https://apicta.org/" target="_blank">APICTA 2021 - The Asia Pacific ICT Alliance Award-2021</a><br>
              <br>
              <p></p>
              <p>In this project, we have worked on simple yet powerful deep network architecture, U2-Net, for salient object detection(SOD) and utilized the architecture in order to improve the efficiency of the “Image Background Removal” & “Ghost Mannequin”.  The design has the following advantages: (1) it is able to capture more contextual information while generating image masking from raw images (2) it increases the depth of the whole architecture without significantly increasing the computational cost because of the pooling operations used in these RSU blocks.</p>
              <br>
            </td>
          </tr>

          <tr>
            <td width="25%">
              <div class="one">
                <div class="two"><img src="Images/IR.jpeg" width="160"></div>
              </div>
            </td>
            <td valign="middle" width="75%">
            <a href="#">
                <papertitle>Automatic Image Resizing from Masking</papertitle>
            </a>
              <br>
              Md Arifur Rahman, <strong>Md Ashikur Rahman </strong>@<a href="https://cutoutwiz.com/" target="=_blank">CutOutWiz</a>
              <br>
              <p></p>
              <p>In this project, we have created a simple yet powerful algorithm (accuracy: ~ 99.15%) that can join all the curves of all the uninterrupted points on the edge and use the U2-Net architecture to automatically resize the image from image masking. The algorithm has the following advantages: (1) it is able to remove unwanted objects, leaving desired objects in the image (2) it is able to automatically margin objects.</p>
              <br>
            </td>
          </tr>


          <tr>
            <td width="25%">
              <div class="one">
                <div class="two"><img src="Images/IRC.jpg" width="160"></div>
              </div>
            </td>
            <td valign="middle" width="75%">
            <a href="#">
                <papertitle>Translucent Image Recoloring through Dominant Color Estimation & Proportionate Color Distribution</papertitle>
            </a>
              <br>
              <strong>Md Ashikur Rahman</strong>, Md Arifur Rahman @<a href="https://cutoutwiz.com/" target="=_blank">CutOutWiz</a>
              <p></p>
              <p>We introduce a deep learning algorithm that learns to find the dominant color and distributes the color ratio over the image matrix. We have shown how this algorithm is able to find the dominant color in an enigmatic palette and distribute the color ratio over the image matrix to recolor. The relational representation achieves the novel performance of this task.</p>
              <br>
            </td>
          </tr>
          </tbody>
          </table>
       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="100%" valign="middle">
              <strong>Selected Projects Named-Entity Recognition</strong>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td width="25%">
              <div class="one">
                <div class="two"><img src="Images/CNER.png" width="160"></div>
              </div>
            </td>
            <td valign="middle" width="75%">
            <a href="#">
                <papertitle>Comprehensive Named Entity Recognition (NER) on De-identification and Heart Disease Risk Factors with Distant Supervision</papertitle>
            </a>
              <br>
              <strong>Md Ashikur Rahman, Thanh Thieu (Assistant Professor, Computer Science, OSU)</strong>
              <br>
              [<a href="https://github.com/LanguageAndIntelligence/Visualization-Annotation/" target="_blank">Code</a>]
               [<a href="https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/" TARGET="_blank">Dataset</a>]
              <p></p>
              <p>CORD-NER methods are domain-independent that can be applied to corpus in different domains. Regarding "De-identification and Heart Disease Risk Factors", we evaluated NER performance comparison between SciSpacy and our annotation results on the N2C2 Dataset  (with 7-9% improvements over previous approaches) and visualized the results on TensorBoard. CORD-NER annotation is a combination from 4 sources:<strong> (Reference: <a href="https://xuanwang91.github.io/2020-03-20-cord19-ner/" target="_blank">here</a> )</strong></p>
              <ol>
                <li>Pretrained NER on 18 General Entity Types: Spacy</li>
                <li>Pretrained NER on 18 Biomedical Entity Types: SciSpacy</li>
                <li>Knowledge Base (KB)-Guided NER on 127 Biomedical Entity Types</li>
                <li>Seed-Guided NER on 9 New Entity Types</li>
            </ol>
            </td>
          </tr>
         <tr>
            <td width="25%">
              <div class="one">
                <div class="two"><img src="Images/NeuroNER.JPG" width="160" vspace="24"></div>
              </div>
            </td>
            <td valign="middle" width="75%">
            <a href="#">
                <papertitle>Named Entity Recognition (NER) on the N2C2 Dataset: Obesity Challenge Factors</papertitle>
            </a>
              <br>
             <strong>Md Ashikur Rahman, Thanh Thieu (Assistant Professor, Computer Science, OSU)</strong>
              <br>
             [<a href="https://github.com/LanguageAndIntelligence/Visualization-Annotation/" target="_blank">Code</a>]
               [<a href="https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/" TARGET="_blank">Dataset</a>]
              <p></p>
              <p>NeuroNER leverages the state-of-the-art prediction capabilities of deep learning and enables the users to create or modify annotations for a new or existing corpus. The NeuroNER engine is based on artificial neural networks (ANNs). Specifically, it relies on a variant of recurrent neural network (RNN) called long short-term memory (LSTM). The NER engine's ANN contains three layers:<strong> (Reference: <a href="http://neuroner.com/" target="_blank">here</a> )</strong></p>
              <ol>
                <li>Character-enhanced token-embedding layer</li>
                <li>Label prediction layer</li>
                <li>Label sequence optimization layer</li>
              </ol>
              <p>On the N2C2 Dataset (Obesity Challenge Factors), we have trained the neural network that performs the NER and evaluated the quality of the predictions made by NeuroNER. Also, we have developed an algorithm that converts NeuroNER output to WebAnno input format. However, the performance metrics can be calculated and plotted by comparing the predicted labels with the gold labels. The evaluation can be done at the same time as the training if the test set is provided along with the training and validation sets, or separately after the training.</p>
            </td>
          </tr>
          </tbody>
          </table>
                 <br><table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>

            <td width="100%" valign="middle">
            <br>
              <strong>More AI/ML projects</strong>
            </td>
          </tr>
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td width="25%">
              <div class="one">
                <div class="two"><img src="Images/TLSTM.png" width="160"></div>
              </div>
            </td>
            <td valign="middle" width="75%">
            <a href="https://github.com/LanguageAndIntelligence/Tree-LSTM" target="_blank">
                <papertitle>Tree LSTM implementation on Molecular Property using PyTorch</papertitle>
            </a>
              <br>
               <strong>Md Ashikur Rahman, Thanh Thieu (Assistant Professor, Computer Science, OSU)</strong>
              <br>
              [<a href="https://github.com/LanguageAndIntelligence/Tree-LSTM" target="_blank">Code</a>]
              [<a href="https://arxiv.org/pdf/1503.00075.pdf" target="_blank">Reference</a>]
              <br>
              <p></p>
              <p>The only underlying LSTM structure that has been explored so far is the linear chain. However, natural language exhibits syntactic features that combine words naturally into phrases. Tree-LSTMs outperform all existing systems and strong LSTM baselines on two tasks: predicting the semantic relatedness of two sentences and classification.</p>
            <br>
            </td>
          </tr>
          <tr>
            <td width="25%">
              <div class="one">
                <div class="two"><img src="Images/BrainTumor.jpg" width="160" vspace="24"></div>
              </div>
            </td>
            <td valign="middle" width="75%">
            <a href="https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification" target="_blank">
                <papertitle>RSNA-MICCAI Brain Tumor Radiogenomic Classification: Predict the status of a genetic biomarker important for brain cancer treatment</papertitle>
            </a>
                <br>
              <strong>Md Ashikur Rahman</strong>
              <br>
              [<a href="https://www.kaggle.com/c/rsna-miccai-brain-tumor-radiogenomic-classification" target="_blank">Kaggle Competition</a>]
                [<a href="https://www.kaggle.com/mdashikrah/notebooke26ea03689/" target="_blank">Notebook</a>]
                <br>
              <p></p>
                <p>A malignant tumor in the brain is a life-threatening condition. Known as glioblastoma, it's both the most common form of brain cancer in adults and the one with the worst prognosis, with median survival being less than a year. The presence of a specific genetic sequence in the tumor known as MGMT promoter methylation has been shown to be a favorable prognostic factor and a strong predictor of responsiveness to chemotherapy.</p>
              <p>We utilize a novel convolutional neural network architecture that optimizes both accuracy and efficiency (FLOPS) on the dataset folders where each of the folders corresponds to each of the structural multi-parametric MRI (mpMRI) scans, in DICOM format.</p>
            </td>
          </tr>
          </tbody>
          </table>
                 <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="100%" valign="middle">
              <strong>More cognitive science/neuroscience projects</strong>
            </td>
          </tr>
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                        <tr>
            <td width="25%">
              <div class="one">
                <div class="two"><img src="./Kelsey Allen_files/cogsci2019_image.png" width="160" vspace="1"></div>
              </div>
            </td>
            <td valign="middle" width="75%">
              <papertitle>Discovering a symbolic planning language from continuous experience</papertitle>
              <br>
              João Loula, Tom Silver, <strong>Kelsey Allen</strong>, Josh Tenenbaum
              <br>
              <em>Cognitive Science Society</em>, 2019
              <br>
              <p></p>
              <p>We present a model that starts out with a language of low-level physical constraints and, by  observing expert demonstrations, builds up a library of high-level concepts that afford planning  and action understanding.</p>
            </td>
          </tr>
          <tr>
            <td width="25%">
              <div class="one">
                <div class="two"><img src="./Kelsey Allen_files/neural.png" width="160" vspace="1"></div>
              </div>
            </td>
            <td valign="middle" width="75%">
              <papertitle>High-dimensional filtering supports context-dependent neural integration</papertitle>
              <br>
              Jonathan Gill, <strong>Kelsey Allen</strong>, Alexander Williams, Mark Goldman
              <br>
              <em>Cosyne</em>, 2019
              <p></p>
              <p>We present a simple method for achieving context-dependent filtering of incoming signals in biologically plausible neural networks. </p>
            </td>
          </tr>
            <tr>
            <td width="25%">
              <div class="one">
                <div class="two"><img src="./Kelsey Allen_files/faces.png" width="160" vspace="1"></div>
              </div>
            </td>
            <td valign="middle" width="75%">
            <a href="http://cbmm.mit.edu/sites/default/files/publications/allen_5_13.pdf">
              <papertitle>Integrating identification and perception: A case study of familiar and unfamiliar face processing.</papertitle>
              </a>
              <br>
              <strong>Kelsey Allen</strong>, Ilker Yildirim, Joshua B Tenenbaum
              <br>
              <em>Cognitive Science Society</em>, 2016  <font color="red"><strong>(Oral Presentation)</strong></font>
              <p></p>
              <p>We present a framework for explaining differences between familiar and unfamiliar face processing which combines feedforward neural networks with non-parametric generative models.</p>
            </td>
          </tr>
            <tr>
            <td width="25%">
              <div class="one">
                <div class="two"><img src="./Kelsey Allen_files/fishing.png" width="160" vspace="1"></div>
              </div>
            </td>
            <td valign="middle" width="75%">
            <a href="https://compdevlab.yale.edu/docs/allen_cogsci2015.pdf">
              <papertitle>Go fishing! Responsibility judgments when cooperation breaks down.</papertitle>
              </a>
              <br>
              <strong>Kelsey Allen</strong>, Julian Jara-Ettinger, Tobias Gerstenberg, Max Kleiman-Weiner, Joshua B Tenenbaum
              <br>
              <em>Cognitive Science Society</em>, 2015
              <p></p>
              <p>We present a coordination game in which three agents must use their knowledge of each others' abilities in order to determine the best action to take. We show that a model which acts to maximize utility under recursive theory of mind, combined with a measure of outcome, best predicts human decisions.</p>
            </td>
          </tr>
          </tbody>
          </table>
                 <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="100%" valign="middle">
              <strong>From my undergraduate days (physics, ants and language)</strong>
            </td>
          </tr>
        </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                       <tr>
            <td width="25%">
              <div class="one">
                <div class="two"><img src="./Kelsey Allen_files/atlas.jpg" width="160" vspace="1"></div>
              </div>
            </td>
            <td valign="middle" width="75%">
            <a href="http://sro.sussex.ac.uk/id/eprint/55408/1/ATLAS_Collaboration_Search_for_high-mass_dilepton_resonances_in_pp_collisions_etc.pdf">
              <papertitle>Search for high-mass dilepton resonances in p p collisions at s= 8 TeV with the ATLAS detector</papertitle>
              </a>
              <br>
              ATLAS Collaboration
              <br>
              <em>Physical Review D</em>, 2014
              <p></p>
              <p>I contributed analyses to determine new limits for particles that might emerge from minimal Z' models.</p>
            </td>
          </tr>
                                           <tr>
            <td width="25%">
              <div class="one">
                <div class="two"><img src="./Kelsey Allen_files/ants.jpg" width="160" vspace="1"></div>
              </div>
            </td>
            <td valign="middle" width="75%">
            <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0141971">
              <papertitle>Interactions increase forager availability and activity in harvester ants</papertitle>
              </a>
              <br>
              Evlyn Pless, Jovel Queirolo, Noa Pinter-Wollman, Sam Crow, <strong>Kelsey Allen</strong>, Maya B Mathur, Deborah M Gordon
              <br>
              <em>PLoS One</em>, 2015
              <p></p>
              <p>We analyzed the foraging patterns of red harvester ants and found that ants which had greater numbers of antennal contacts with returning foragers were more likely to leave the nest to forage. </p>
            </td>
          </tr>
          <tr>
            <td width="25%">
              <div class="one">
                <div class="two"><img src="./Kelsey Allen_files/disagreement.jpg" width="160" vspace="1"></div>
              </div>
            </td>
            <td valign="middle" width="75%">
            <a href="https://www.aclweb.org/anthology/D14-1124">
              <papertitle>Detecting disagreement in conversations using pseudo-monologic rhetorical structure</papertitle>
              </a>
              <br>
              <strong>Kelsey Allen</strong>, Giuseppe Carenini, Raymond Ng
              <br>
              <em>EMNLP</em>, 2014
              <p></p>
              <p>We developed a new set of features based on the automatically generated rhetorical structure of online forum conversations, and show that these features are helpful for detecting disagreement.</p>
            </td>
          </tr>


        </tbody></table>
         <table width="100%" cellspacing="0" cellpadding="20" border="0" align="center">
      <tbody><tr>
        <td>
        </td>
      </tr>
    </tbody>
  </table>
      </td>
    </tr>
  </tbody></table>

  <div id="footer-container">

<!-- #footer -->



	</div><!-- #footer-container -->

